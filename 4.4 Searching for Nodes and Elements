4.4 Searching for Nodes and Elements

Навигация по структуре HTML

Все примеры мы будем тестировать на нашем тренажере. - https://parsinger.ru/html/index1_page_1.html

BeautifulSoup создает объект из HTML-дерева, по которому мы можем осуществлять необходимую нам навигацию и поиск элементов.

Самые простые и понятные методы, которыми мы пользуемся, когда пишем наши парсеры, это:

- .find() - Возвращает искомый элемент, узел HTML.
- .find_all() - Возвращает список элементов. Часто используется вместе с .find()

.find()

Давайте разбираться как работает этот метод на конкретном примере

Унас есть сайт (https://parsinger.ru/html/index1_page_1.html), и мы хотим получить элемент, который имеет class= 'item'

from bs4 import BeautifulSoup
import requests

url = 'https://parsinger.ru/html/index1_page_1.html'
response = requests.get(url=url)
respoinse.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'lxml')
div = soup.find('div', 'item')
print(div)

Здесь все очень просто: мы даем указание найти конкретный div, который имеет конкретный class = 'item' Все:) В ответ получим <class 'bs4.element.Tag'>,
элемент класса bs4, с которым мы можем работать дальше.

.find_all()

Давайте посмотрим на содержимое тега, который мы получили. Видим, что мы имеем в своем распоряжении все те же элементы HTML. Давайте попробуем получить все теги <li>.
Для этого нам понадобится метод .find_all().

from bs4 import BeautifulSoup
import requests

url = 'http://parsinger.ru/html/index1_page_1.html'
response = requests.get(url=url)
response.encoding = utf-8'
soup = BeautifulSoup(response.text, 'lxml')
div = soup.find('div', 'item').find_all('li')
print(div)

>>>[<li>Бренд: Jet</li>, <li> Тип: умные часы</li>, <li>Материал корпуса: пластик</li>, <li>Технология экрана: Монохромный</li>]

Обратите внимание, что мы получили список всех элементов <li> вместе с содержимым. Нам бы хотелось избаавиться от тегов и получить только содержимое.
Метод .text к списку мы применить не можем, а вот пройтись по списку в цикле for и в цикле извлечь текст каждого тега это запросто.

from bs4 import BeautifulSoup
import requests

url = 'http://parsinger.ru/html/index1_page_1.html'
response = requests.get(url=url)
reponse.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'lxml')
div = soup.find('div', 'item').find_all('li')
for txt in div:
  print(txt.text)

>>> Бренд: Jet
Тип: умные часы
Материал корпуса: пластик
Технология экрана: Монохромный

Вот и все? мы с вами извлеклли данные, которые находились в описании к товару.

p.s. Чтобы не городить цикл в две строки, мы можем возпользоваться list comprehension:

div = [x.text for x in soup.find('div', 'item').find_all('li')]

То же самое что и...

result = []
for txt in div:
  result.append(txt)

Такой подход возможен  потому что .find_all('li') вернул нам список состоящий из элементов li


Поиск по class, id, поиск по атрибутам

Поиск по class

Поиск по class аналогичен поиску по id, за исключением небольших различий в синтаксисе.
Будем использовать наш тренажер - https://parsinger.ru/html/headphones/5/5_32.html. Мы с вами хотим получить значение тега <p> с классом 'article'

from bs4 import BeautifulSoup
import requests

url = 'http://parsinger.ru/html/headphones/5/5_32.html'
response = requests.get(url=url)
response.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'lxml')
div = soup.find('p', class_='article').text
pritn(div)

>>>Артикул: 80387567

Стоит обратить внимание на нижнее подчеркивание после слова class_. Это не опечатка, так сделано специально, чтобы не возникало конфликтов с остальным кодом на
python. class - служебное слово, которым объявляются классы, и так называть переменные или атрибуты в python нельзя. Стоит просто запомнить данный синтаксис.

Также обратите внимание на метол .text, мы его применили во время вызова метода .find(), это хорошая практика. Но новички часто пытаются применить метод .text
к списку, который возвращается при вызове метода .find_all()

Поиск по id

На этой же странице нашего тренажера есть тег <p> with id='p_header'. Давайте посмотрим как извлекать текст по id.

from bs4 impot BeautifulSoup
import requests

url = 'http://parsinger.ru/html/headphones/5/5_32.html'
response = requests.get(url=url)
response.encoding='utf-8'
soup=BeautifulSoup(response.text,'lxml')
div=soup.find('p',id='p_header').text
print(div)

>>>Наушники HP Pavilion Gaming 600

На самом деле, тут все выглядит точно так же, как и при работе с class_='', только нам нужно указать, что мы ищем id.

Поиск по атрибутам

У нас есть тег span, у которого есть атрибут name='count'. Давайте посмотрим, как извлечь текст по атрибуту.

from bs4 import BeautifulSoup
import requests

url='http://parsinger.ru/html/headphones/5/5_32.html'
response=requests.get(url=url)
response.encoding='utf-8'
soup = BeautifulSoup(response.text, 'lxml')
div=soup.find('span',{'name':'count'}).text
print(div)

>>>В наличии: 38

В реальных условиях поиск по атрибутам приходится использовать не очень часто, но важно знать, что такие возможности у нас есть, и ими не стоит пренебрегать.

Задание

1. Открываем сайт - https://parsinger.ru/html/index1_page_1.html
2. Извлекаем при помощи bs4 данные о стоимости часов (всего 8шт)
3. Складываем все числа
4. Вставляем результат в поле ответа

Решение:
from bs4 import BeautifulSoup
import requests

url = 'https://parsinger.ru/html/index1_page_1.html'
response = requests.get(url)
response.encoding = 'utf-8'  # <-- Явно задаём правильную кодировку
soup = BeautifulSoup(response.text, 'lxml')

# Находим все теги с ценой — это <p class="price">
prices = soup.find_all('p', class_='price')

# Извлекаем числа, убираем "руб" и переводим в int
total = sum(int(price.text.replace(' руб', '')) for price in prices)

print('Сумма цен:', total)
(Хуй знает правильно или нет ChatGPT iDONi желает тебе здоровье)
