8.7 aiohttp

Введение в aiohttp

Установка: pip install aiohttp

Импорт: import aiohttp

Для асинхронных запросов к серверу нам не подойдет стандартная библиотека requests, которой мы 
пользовались ранее. Для этого существует асинхронная библиотека запросов aiohttp.

aiohttp(documentation-https://docs.aiohttp.org/en/stable/) - асинхронный ввод/вывод для http-запросов.
Он был реализован на базе asyncio, использующей модель кооперативной многозадачности. Как мы уже знаем,
в python существует GIL, который не позволяет двум потокам работать одновременно, заставляя весь код
работать последовательно. При написании парсеров можно обойтись без асинхронного кода и писать простые 
парсеры для фриланса или для своих целей. Но пытливый ум программиста заставляет каждого из нас продолжать
учиться и совершенствовать свои навыки. Именно поэтому и был придуман модуль aiohttp для асинхронных
запросов к серверу. Aiohttp изначально создавался для высоконагруженных систем, которые должны
выдерживать огромное количество запросов в секунду, но нам он нужен для ускорения наших парсеров, с чем
данный модуль справляется на отлично.

Aiohttp имеет подробную документацию, в которой можно найти все ответы на свои вопросы, что является
дополнительным аргументом для выбора его в качестве рабочего инструмента.

Aiohttp

Сейчас будет самый простой пример асинхронного запроса. На полноценный парсер это еще не похоже, т.к.
выполняется всего один запрос, но для старта нам подойдет.

Первым делом необходимо создать сессию. Сессия обладает набором параметров по умолчанию, которые
передаются серверу с каждым запросом в рамках этой сессии. Самый важный параметр - это cookie,
которые являются общим для всех запросов сессии.

В коде ниже мы создали сессию при помощи менеджера контекста with. Это нужно для того, чтобы после
выполнения всех запросов aiohttp очистил все ресурсы.

Если у вас не запускается код ниже, то удалите следующую строку.

asyncio.set_event_loop_policy(asyncio.WindowaSelectorEventLoopPolicy())

import aiohttp
import asyncio

async def main():
#---------------------start block 2---------------------

async with aiohttp.ClientSession(trust_env=True) as session:
  async with session.get('https://parsinger.ru/html/index1_page_1.html') as response:
    print(await response.text())
#-------------------end block 2-------------------

#--------------------start block 1 ---------------------------
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
#--------------------start block 1 --------------------------

При выполнении этого когда происходит следующее. Интерпретатор, проходя по коду сверху вниз,
инизиализирует нашу корутину async def main() в блоке №2, на этом этапе запуск еще не происходит. 
Когда интерпретатор доходит до блока №1, он применяет политику, по правилам которой будет работать
цикл событий, это происходит в первой строке первого блока, об этом мы говорили в разделе про
event loop. Когда интерпретатор доходит до второй строки блоки №1, где мы передаем нашу корутину
на выполнение в цикл событий asyncio.run(main()), именно в этот момент происходит ее выполнение.

Вся магия асинхронного запроса происходит в блоке №2. Первая строка этого блока создает с помощью
менеджера контекста with асинхронную сессию, которая может быть передана в другую корутину. Но в этом
примере она используется в той же корутине. Во второй строке второго блока мы используем метод
.get(url="") для передачи этой сессии ссылки для асинхронного запроса. В следующих запросах мы 
поговорим о том, как передать в него целый список ссылок и как обработать их асинхронно.

На этом этапе уже можно понять, как мы будем использовать bs4 для извлечения нужных элементов со
странице, но об этом чуть позже.

В третьей строке мы печатаем все содержимое ответа. У вас может появиться справедливый вопрос: а
почему мы написали await в функции print()? Т.к. response работает в сетью, возвращая нам результат
своей работы через устройство ввода/вывода, т.е. через HDD/SSD/M2 и т.д., код вынужден ждать, пока 
произойдет эта операция. Если бы у нас было больше запросов чем один, в этом месте произошло бы
переключение контекста на другой запрос.

Как можно заметить, переменная response ведет себя почти так же, как и в синхронной библиотеке
requests, о чем мы и поговорим в следующем абзаце.

Какое содержимое мы можем получить от переменной response?

1. await response.text() - возвращает содержимое страницы, весь HTML.
2. response.content(без использования await) - возвращает размер содержимого в байтах
<StreamReader 7875 bytes eof>
3. response.status(без использования await) - вохвращает статус код ответа.
4. response.url(без использования await) - возвращает текущий URL на который выполнялся запрос.
5. await response.read() - возвращает содержимое страницы в байтовом виде, на примере тега title это
наглядно видно.

*<title>\x68\xa3\xd1\x87\x6B\x68\x68\xbc\xd1\x81\x81\x87
xdB\xbfd\x6B\x01\x88\xd1\x81\xdB\xhB\xd1\x82\x61\x8c</title>

6. await response.json() - возвращает результат в формате JSON, в том случае, если сервер готов нам его
отдать.
