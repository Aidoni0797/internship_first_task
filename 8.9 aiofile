8.9 aiofile

Aiofiles введение

Установка
pip install aiofiles
Импорт
import aiofiles

Aiofiles(документация - https://github.com/Tinche/aiofiles) - отличная библиотека для асинхронного
скачивания медиа-файлов из сети интернет. С ее помощью мы можем ускорить загрузку файлов и чтение
больших текстовых файлов практически в 10 раз. В этом разделе курса мы сравним синхронный и 
асихронный способы скачивания изображений и видео с нашего сайта-тренажера, чтобы наглядно
продемонстрировать разницу в скорости.

Aiofiles может работать не только с файлами, которые хранятся на вашем компьютере, прелесть работы
с этой библиотекой в том, что она умеет работать с response.content, а этот именно то что нужно для создания
асинхронной загрузки файлов.

Функция open() из aiofiles работает почти так же, как и привычная всем синхронная функция open(),
встроенная в Python. Мы можем использовать асихронную версию функцию open() как с менеджером
контекста with, так и без него.

Простой пример использования aiofiles
import aiofiles
import asyncio

C использованием менеджера контекста with

async with aiofiles.open('filename', mode='r') as f:
  contents = await f.read()
print(contents)

Результат
  'My file contents'

Без использования менеджера контекста with

file = await aiofiles.open('filename', mode='r')
contents = await file.read()
file.close()
print(contents)

При использовании асинхронной функции open() из библиотеки aiofiles необходимо закрывать файл
file.close(), в том случае если мы не использовали контекстный менеджер with. С применением
контекстного менеджера with файл закроется самостоятельно после прочтения файла.

Асинхронная функция open() имеет такие же атрибуты, как ее синхронный брат.

- aiofiles.open('folder/file.txt') - абсолютное или относительное значение пути к файлу;
- aiofiles.open(mode='') - необязательный атрибут, который указывает режим работы с файлом
- mode = 'r' - открывает файл только для чтения, установлен по умолчанию;
- mode = 'w' - открывает файл  для записи, существующий файл будет перезаписан, а если файл существует,
то он будет создан;
- mode = 'x' - бросает исключение FileExistsError, если файл с таким именем уже существует;
- mode = 'a' - открывает файл для добавления данных в конец файла;
- mode = 't' - символ текстового режима;
- mode = 'b' - символ двоичного режима, для записи медиа-файлов;
- mode = 'wb' - открывает файл для записи в бинарном режиме, именно этот режим мы будем использовать
для скачивания файлов;
- aiofiles.open(buffering = -1) - не обязательный аргумент, используется для политики буферизации;
- buffering = -1 - значение по умолчанию;
- buffering = 0 - построчная буферизация, только для бинарного режима;
- buffering = 1 - построчная буферизация для текстовго файла;
- encoding='utf-8' - необязательный аргумент, используется для кодирования или декодирования файла, 
этот аргумент следует использовать только для текстовго файла;
- errors = None - None по умолчанию, необязательный аргумент, указывает, как должны обрабатываться ошибки
кодирования и декодирования, только для текстовых файлов;
- errors = 'strict' - бросает исключение ValurError, то же самое что и None;
- errors = 'ignore' - игнорирует ошибки кодирования, данные могут быть потеряны;
- errors = "surrogateescape" - любые некорректные байты будут представлены как символы Юникода, при
обратной операции символы будут преобразованы обратно в байты;
- errors = "xmlcharrefreplace" - символы, которые не поддерживаются указанной кодировкой, будут заменены
соответствующей ссылкой на символ XML
- newline = 'None' - None по умолчанию, определяет работу режима новой строки, только для текстовых файлов;
- newline='\n' - установит разделитель строки, указанный в кавычках;
- newline="\r\n" - файл будет прочитан как одна большая строка;
- closefd=True - True по умолчанию, если установить False, то файловый дескриптор не будет закрыт даже
после команды file.close();
- loop = None - None по умолчанию, если loop отсутствует, будет выбран event loop по умолчанию
в соответствии с установленной политикой asyncio.
- excutor = "name_loop" - принимает экземпляр класса event loop, по умолчанию None, будет выбран цикл
событий по умолчанию name_loop = asyncio.get_event_loop();

Aiofiles имеет в своем арсенале асинхронные копии привычных для всех чтения и записи файлов, а 
именно readline, readlines, write, writelines о них мы и поговорим ниже. На самом деле их больше,
познакомиться с ними можно в документации, а для наших целей хватит и перечисленных. Все эти функции
должны быть использованы с ключевым словом await, потому что когда вы работает с файлами в момент
чтения или записи, цикл событий будет переключать контекст для открытия следующего.

- await file.writelines(str) - записывает в файл указанную последовательность строк.

Этот код генерирует  и записывает в файл построчно. 100к рандомных чисел от 10 к до  100 к

import time
import aiofiles
import asyncio

async def write_numbers():
  async with aiofiles.open('one_million.txt', mode='a') as file:
    for x in range(1,100000):
      await file.writelines(str(random.randint(10000, 100000))+'\n')

start = time.perf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorLoopPolicy())
asyncio.run(write_numbers())
print(time.perf_counter() - start)

Результат:
  8.32808830001159

await file.write(str) - записывает в файл указанную строку.

Этот код генерирует и записывает файл целиком миллион чисел от 100к до 1кк

import time
import aiofiles
import asyncio

async def write_number():
  async with aiofiles.open('async_write_n\million_numbers.txt', mode='w') as file:
    numbers = str([x for x in range(100000, 1000001)])
    awaot file.write(numbers)

start = time.perf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(write_numbers())
print(time.perf_counter() - start)

Результат:
  0.1362756000016816

- await file.readlines(str) - считывает из файла все строки в список и возвращает его. Для запуска 
кода ниже и следующего вам понадобиться файл, сгенерированный прошлым кодом, этот файл можно скачать тут
import time
impotr aiofiles
import asyncio

Этот код читает файл построчно миллион строк.

async def gen_numbers():
  async with aiofiles.open('async_one_million.txt', mode='r') as file:
    text = await file.readlines()
    print(text)

start = time.perf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(gen_numbers())
print(time.perf_counter() - start)

- await file.readline(str) - считывает из файла одну строку и возвращает её

import time
import aiofiles
import asyncio

Этот код читает файл построчно миллион строк.
async def gun_numbers():
  async with aiofiles.open('async_one_million_numbers.txt', mode='r') as file:
    text = await file.readline()
    print(text)

start = time.perf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(gen_numbers())
print(time.perf_counter() - start)

aiofiles начало

Если ваша цель - обработать построчно один большой текстовый файл при помощи aiofiles, то вам следует
использовать привычный способ чтения, а именно синхронной функцией open(). Скорость будет выше,
чем при использовании асинхронной функции open(), все потому, что при чтении файла его содержимое
загружается в оперативную память и дальнейшая работа в асинхронном стиле будет хоть и доступна,
но мало эффективна в связи с тем, что asyncio делает много всего "под капотом". Для такой простой 
операции как чтение одного файла не стоит использовать асинхронку.

Давайте усбедимя в этом на практике. Скачайте file_1.txt, в котором 100000 строк, поместите его в
папку с вашим проектом, он понадобится для запуска следующего кода, в котором мы будем сравнивать
скорость его чтения в синхронном и асинхронном стиле.

import time
import aiofiles
import asyncio

async_time = float()

def sync_read():
  start = time.perf_counter()
  with open(f'file_text/file_1.txt', 'r') as file:
    for line in file.readlines():
      print(line.strip())
  sync_time = round(time.perf_counter() - start, 5)
  return sync_time

async def async_read():
  start = time.perf_counter()
  async with aiofiles.open('file_text/file_1.txt', mode='r') as file:
    async for line in file:
      print(str(line).strip())
    async_time = round(time.perf_counter()-start, 5)
    return print(f'Файл считан построчно в асинхронном стиле за {async_time} сек')

sync = sync_read()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(async_read())
print(f'Файл считан построчно в синхронном стиле за {sync} сек')

Результат

Файл считан построчно в асинхронном стиле за 9.16715 сек
Файл считан построчно в синхронном стиле за 0.47808 сек

В этом примере мы видим, что чтение в синхронном стиле заняло куда меньше времени, чем
в асинхронном. Так происходит потому, что каждая строка в асинхронной функции была преобразована в корутину,
а на это уходит много времени. Также  функция print() отнимает приличное количество времени во время
вызова и справедливости ради, принты есть в обеих функциях.

В следующем примере мы откроем сразу 100 текстовых файлов и прочитаем каждый, Как думаете какой
подход победит по скорости?

Для запуска кода ниже вам надобится файл file_text.rar, который необходимо разархивировать в папку
с проектом.

import time
import aiofiles
import asyncio

path = os.listdir('file_text')

def sync_mass_read(path):
  start = time.perf_counter()
  for file in path:
    with open(f"file_text/{file}", 'r') as f:
      for line in f:
        print(line.strip())
  sync_time = round(time.perf_counter()-start,5)
  return sync_time

async def async_mass_read(path):
  start = time.perf_counter()
  for file in path:
    async with aiofiles.open(f"file_text{file}", mode='r') as f:
      async for line in f:
        print(str(line).strip())
    async_time = round(time.perf_counter()-start,5)
    return print(f"Файл считан построчно в асинхронном стиле за {async_time} сек")

sync = sync_mass_read(path)
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(async_mass_read(path))
print(f"Файл считан построчно в синхронном стиле за {sync} сек")

Результат

  Файл считан построчно в асинхронном стиле за 8.66915 сек
  Файл считан построчно в синхронном стиле за 125.47881 сек

Видим что результат асинхронного подхода превзошел синхронный в 15 раз. У вас финиальные цифры могут
отличаться, они зависят от скорости вашего железа. Какой же вывод можно сделать из этого? А ввод такой,
что нет смысла работать с одним файлом в асинхронном стиле. Асинхронка идеально подходит для работы с
множественным вводом/выводом, и нцжно четко понимать и различать, где стоит ее применять, а где нет.
Такая же ситуация сохранится, если мы захотим скачать большое видео из сети интернет.

Конечно, такой код не может быть использовать без цикла событий или в синхронной программе, давай
изменим его, добавим в него все необходимое и скачаем свой первый файл с помощью aiofiles.

Перед запуском этого кода создайте папку video, в которую будет сохранен скачанный файл

import aiofiles
import asyncio
import aiohttp

async def async_write(url):
  async with aiohttp.ClientSession() as session:
    async with aiofiles.open('video/async_video_async.mp4', mode='wb') as video:
      async with session.get(url) as response:
        async for piece in response.content.iter_chunked(5120):
          await video.write(piece)

url = 'https://parsinger.ru/asyncio/aiofile/1/video/nu_pogodi.mp4'
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(async_write(url))

Загрузка видео в асинхронном стиле

Aiofiles не умеет творить чудеса, она всего лишь работает асинхронно с вашими файлами. Если вы
захотите скачать один большой видео-файл из интернета, вы не добьетесь большей скорости, чем при
обычном скачивании. Чтобы это продемонстрировать, я загрузил на хостинг мультик Ну, погоди, кторый весит
212 мб.

Код ниже сачает видео файл размером 212 мб дважды, сперва в синхронном стиле, а затем в асинхронном, и
после завершения скачивания напечатает время скачивания. Создайте папку video в своем проекте для
сохранения видеофайла и запустите код ниже, скорость скачивания будет зависеть от скорости вашего 
интернет-соединения.

import requests
import time
import aiofiles
import asyncio
import aiohttp

url = "https://parsinger.ru/asyncio/aiofile/1/video/nu_pogodi.mp4"

def sync_write():
  with open ('video/sync_video_async.mp4', 'wb') as video:
    response = requests.get(url, stream=True)
    for piece in response.iter_content(chunk_size=5120):
      video.write(piece)

async def async_write():
  async with aiohttp.ClientSession() as session:
    async with aiofiles.open('video/async_video_async.mp4', mode='wb') as video:
      async with session.get(url) as response:
        async for piece in response.content.iter_chunked(5120):
          await video.write(piece)

start = time.perf_counter()
sync_write()
print(f'Сохранено синхронным способом за {round(time.perf_counter()-start,3)} сек')

start = timeperf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(async_witer())
print(f'Сохранено асинхронным способом за {round(time.perf_counter()-start, 3)} сек')

#Результат
  Сохранено синхронным способом за 60.593 сек
  Сохранено асинхронным способом за 58.765 сек


Скачивание картинок в асинхронном стиле

К этому этапу курса вы уже умеете скачаиьтва изображения при помощи bs4 и requests, в этом разделе мы
рассмотрим скачивание 100 картинок, и сравним скорость асинхронного скачивания и синхронного.

Для запуска этого кода создайте папку images для сохранения изображений. Все изображения будут скачаны
с этого сайта - https://parsinger.ru/asyncio/aiofile/1/index.html.

import time
import aiofiles
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import os

async def write_file(session, url, name_img):
  async with aiofiles.open(f'images/{name_img}', mode='wb') as f:
    async for x in response.content.iter_chunked(1024):
      await f.write(x)
    print(f'Изображение сохранено {name_img}')

asyn def main():
  url = 'https://parsinger.ru/asyncio/aiofiles/1/index.html'
  async with session.get(url) as response:
    soup = BeautifulSoup(await response.text(), 'lxml')
    img_url = [f'https://parsinger.ru/asyncio/aiofile/1/{x["src"]}' for x in soup.find_all('img')]
    tasks = []
    for link in img_url:
      name_img = link.split('/')[7]
      task = asyncio.create_task(write_file(session, link, name_img))
      tasks.append(task)
    await asyncio.gather(*tasks)

start = time.perf_counter()
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
print(f'Сохранено изображений {len(os.listdir("images/"))} за {round(time.perf_counter()-start,3)} сек')

Результат
  Сохранено 100 изображений за 7.732 сек

В этом коде используется две корутины, main() и write_file(), давайте вместе разбираться что делает
каждая из них.

- Корутина main() - является точкой входа, именно ее мы передаем для запуска всего асинхронного кода
в цикл событий asyncio.run(main()), после ее запуска происходит следующее:

1. Инициализируется переменная url= с указанием ссылки, куда будет отправлен запрос для дальнейшего
извлечения изображения.
2. Создается ClientSession() с применением диспетчера контекста для создания запросов через эту сессию и
своевременного закрытия сессии;
3. Использование метода session.get(url) с менеджером контекста для своевременного закрытия после
получения ответа;
4. Создается экземпляр супа BeautifulSoup(await response.text(), 'lxml') в который мы передаем объект
response.text() со стоящим рядом ключевым словом await для переключения контекста в цикле событий,
парсеры можно использовать любые, все они перечислены тут;
5. Переменная img_url= генерирует список ссылок, которые были извлечены из супа soup.find_all('img'),
каждая ссылка имеет окончательный вид https://parsinger.ru/asyncio/aiofile/1/img/166246153613344.jpg;
6. Переменная tasks=[] будет служить контейнером для наших тасков которые мы будем помещать в цикл событий;
7. В цикле for link in img_url: мф делаем следующее:
- name_img = link.split('/')[7] извлекаем из каждой  ссылки только ее имя 166246153613344 которое
нам понадобится для именования каждого скачанного изображения;
- task = asyncio.create_task(write_file(session, link, name_img)) функция create_task() оборачивает
корутину в задачу task и планирует ее выполнение. Тут важно вспомнить, что результат выполнения 
корутины является корутиной. По этой причине список tasks будет наполнен заплонированными
к выполнению корутинами, если мы посмотрим на тип объекта, создаваемого каждой итерации цикла,
то увидиим, что его тип <class '_asyncio.Task'>;

- Кроме создания тасков, в этой строке передаются данные, которые мы извлекли в текущей корутине,
в корутину write_file(session, link, name_img), а именно открытую сессию, ссылку на изображение и имя 
изображения. Про эту корутину мы подробно поговорим ниже;

- Когда список tasks = [] наполнен, мы распоковываем список, передаем его в цикл событий при 
помощи функции await asyncio.gather(*tasks), функция .gather() одновременно запускает
все awaitable-объекты из списка tasks=[];

- Корутина write_file(session, url, name_img) выполняется после основной корутины main() и выполняет
запись в файл объекта response.content, т.к. ссылки на изображения прямые .jpg. Также обратите внимание
на асинхронный цикл async for, он выполняет асинхронное итерирование по байтовому содержимому файла
т.е. получая объект и полный набор байт, он записывает в файл те части, которые он обрабатывает в данную
итреацию. Но т.к. каждая картинка весит не более 1,5 мб, файлы качаются практически целиком.
Надеюсь вы помните что итерирование по файлу полезно, когда вы работаете с большими объектами.
Также .iter_chunked(1024) можно удалить полностью, и скрипт продолжит работать медленнее примерно
на одну-две секунды. Применять или не применять итерирование по файлу, решать вам. Но при скачивании
огромного количества изображений эти одна-две секунды превратятся в целые минуты, а мы ведь хотим
добиться скорости работы наших парсеров.
Для сравнения этих двух подходов я подготовил синхронную версию кода, который делает то же самое,
что и код выше. Для его запуска создайте папку sync_save_files в вашем проекте, туда будут сохранены все 
скаченные изображения.

import time
import requests
from bs4 import BeautifulSoup

def main(url):
  img_url = []
  response = requests.get(url)
  soup = BeautifulSoup(response.text, 'lxml')
  images_link = [f'https://parsinger.ru/asyncio/aiofile/1/{x["src"]}' for x in soup.find_all('img')]
  img_url.extend(
